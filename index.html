<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>SharpContour: A Contour-based Boundary Refinement Approach for Efficient and Accurate Instance Segmentation</title>
    <link rel="stylesheet" href="w3.css">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/js/bootstrap.min.js" integrity="sha384-OgVRvuATP1z7JjHLkuOU7Xw704+h835Lr+6QL9UvYjZE3Ipu6Tp75j7Bh/kR0JKI" crossorigin="anonymous"></script>
    <meta name="google-site-verification" content="vIrKe6Ecwa3TVjmMt0OaJpDGw_SJa5IxzTA86wU44QE" />
</head>

<body>

<br/>
<br/>

<div class="w3-container" id="paper">
    <div class="w3-content" style="max-width:850px">
  
    <h2 align="center" id="title"><b>SharpContour: A Contour-based Boundary Refinement Approach for Efficient and Accurate Instance Segmentation</b></h2>
    <br/>
    <!-- <p align="center" id="title">Conference Name (NAME), YYYY.</p> -->

    <p align="center" class="center_text" id="authors">
        <a target="_blank" >Chenming Zhu</a><sup>1 &dagger;</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" >Xuanye Zhang</a><sup>3 &dagger; </sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
       <a target="_blank" >Yanran Li</a><sup>4</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" >Liangdong Qiu</a><sup>1,3</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" >Kai Han</a><sup>3</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a target="_blank" href="https://mypage.cuhk.edu.cn/academics/hanxiaoguang/">Xiaoguang Han</a><sup>1,2 &Dagger;</sup>
        &nbsp;&nbsp;&nbsp;&nbsp;        
    </p>
    <p class="center_text" align="center" id="comments">
        <sup>&dagger;</sup>The two authors contribute equally to this paper
    </p>
    <p class="center_text" align="center" id="comments2">
        <sup>&Dagger;</sup>Corresponding email: hanxiaoguang@cuhk.edu.cn  
    </p>
    <p class="center_text" align="center">
        <sup>1</sup>SSE, The Chinese University of Hong Kong, Shenzhen
        &nbsp; &nbsp; &nbsp;
        <sup>2</sup>FNii, The Chinese University of Hong Kong, Shenzhen  <br>
        &nbsp; &nbsp; &nbsp;
        <sup>3</sup>Shenzhen Research Institute of Big Data  
        &nbsp; &nbsp; &nbsp;
        <sup>4</sup>Birmingham University
        &nbsp; &nbsp; &nbsp;
        <sup>5</sup>The University of Hong Kong
        &nbsp; &nbsp; &nbsp;        
    </p>

    <h5 align="center" id="cvpr"><b><font color=RoyalBlue>CVPR2022</font></b></h3>
    <br>
    <center>
    <img src="teaser.bmp" style="max-width:50%" /></a>
        <p align="center"p><b>Fig. 1 Instance segmentation with SharpContour. </b> <br>
        <b>Top:</b> A is the coarse mask predicted by Mask R-CNN and B is the refinement result of SharpContour. <br>
        <b>Bottom:</b> C is the coarse contour generated by DANCE and D is the refinement result of SharpContour. <br>
        In the corner areas, SharpContour yields significant improvements. </p>
    </center><br>
<!--         <h4 align="center" id="title"><b>Submit to our ScanRefer Localization Benchmark <a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank">here</a>!</b></h4>
        <br><center><a href="http://kaldir.vc.in.tum.de/scanrefer_benchmark/" target="__blank"><img src="teaser.png" style="max-width:100%" /></a></center><br> -->

        
        <h3 class="w3-left-align" id="video"><b>Introduction</b></h3>
        <p>
            Excellent performance has been achieved on instance segmentation but the quality on the boundary area remains unsatisfactory, which leads to a rising attention on boundary refinement. 
            For practical use, an ideal post-processing refinement scheme are required to be accurate, generic and efficient. 
            However, most of existing approaches propose pixel-wise refinement, which either introduce a massive computation cost or design specifically for different backbone models. 
            Contour-based models are efficient and generic to be incorporated with any existing segmentation methods, but they often generate over-smoothed contour and tend to fail on corner areas. 
            In this paper, we propose an efficient contour-based boundary refinement approach, named SharpContour, to tackle the segmentation of boundary area. 
            We design a novel contour evolution process together with an Instance-aware Point Classifier. 
            Our method deforms the contour iteratively by updating offsets in a discrete manner. 
            Differing from existing contour evolution methods, SharpContour estimates each offset more independently so that it predicts much sharper and accurate contours. 
            Notably, our method is generic to seamlessly work with diverse existing models with a small computational cost. 
            Experiments show that SharpContour achieves competitive gains whilst preserving high efficiency

        </p>

        <h3 class="w3-left-align" id="video"><b>Video</b></h3>
        <p>
        <!--         <iframe width="850" height="480" src="https://www.youtube.com/embed/T9J5t-UEcNA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
         -->  
        <center>
        <iframe width="640" height="480" src="SharpContour.mp4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </p>


        <h3 class="w3-left-align" id="publication"><b>Publication</b></h3>
        <!-- European Conference on Computer Vision (ECCV), 2020. <br/> -->
        <!-- <a href="davezchen_eccv2020_scanrefer.pdf" target="__blank">Paper</a>  -->
        <p class="w3-left-align">
        Paper - Coming soon<!--<a href="https://arxiv.org/pdf/???" target="__blank">ArXiv - pdf</a> (<a href="https://arxiv.org/abs/2012.???" target="__blank">abs</a>)-->  | <a href="https://github.com/RudyQ/3DCaricShop" target="__blank">GitHub</a>
        </p>
        <center>
            <a href="https://arxiv.org/pdf/2012.???" target="__blank"></a>
        </center><br>

        <p class="w3-left-align">If you find our work useful, please consider citing it:</p>
        <pre class="w3-panel w3-leftbar w3-light-grey" style="white-space: pre-wrap; font-family: monospace; font-size: 11px">

        
        Coming soon
        </pre>

        
        <h3 class="w3-left-align" id="Method"><b>Method</b></h3>
        <p class="w3-left-align">
        SharpContour obtains the initial contour from coarse segmentation results and deforms the contour to achieve boundary refinement. 
        Fig. 2 shows the deformation process of SharContour: <br>
        1) SharpContour obtains the normal direction. <br>
        2) SharpContour predicts the inner/outer state of vertex to decide negative/positive normal direction of deformation. <br>
        3) SharpContour decides the step size. <br>
        4) SharpContour obtains the moving step number based upon the position of the flipping point. <br>
        5) SharpContour estimates the offsets and deforms the contour. </p>
        <center>
            <img src="ppl6.bmp" style="max-width:80%" /></a>
        </center><br>
        <p align="center"p><b>Fig. 2 Contour Evolution of SharpContour.</b> <br>

        <h3 class="w3-left-align" id="Result"><b>Result</b></h3>
        <h5 class="w3-left-align" id="Qua"><b>Qualitative Results</b></h5>
        <p class="w3-left-align"><b>COCO</b> 
            Fig. 3 shows the results of COCO datasets. We use SharpContour to refine the segmentation results of different models and The top
            line is the results of DANCE while the bottom line is the results of Mask-RCNN. For each example, the left is the result before refinement
            while the right is our result. As is illustrated, SharpContour can refine the segmentation results near instance boundary. </p>
        <center>
            <img src="gallery.bmp" style="max-width:80%" /></a>
        </center>
        </center>
        <p align="center"p><b>Fig. 3 Qualitative Results on COCO datasets </b> <br></p>
        <center>
        
        <p class="w3-left-align"><b>CityScapes</b> Fig. 4 shows the refinement results of SharpContour on the CityScapes datasets. 
            For each example, the left is the result of Mask R-CNN while the right is our result. 
            SharpContour can ameliorate the contour near instance boundary. </p>
        <center>
        <center>
            <img src="gallery_city.bmp" style="max-width:80%" /></a>
        </center>
        <p align="center"><b>Fig. 4 Qualitative Results on CityScapes datasets </b> <br></p>

        <h5 class="w3-left-align" id="Qua"><b>Quantitative Results</b></h5>
        <p class="w3-left-align"><b>COCO</b> Tab. 1 shows the quantitative results of SharpContour on the COCO datasets. 
            AP<sub>dev</sub> denotes the evaluation results on test−dev, and other columns denotes the
            evaluation results on val2017. “Mask R-CNN” is a original Mask R-CNN, and “Mask R-CNN*” is the improved version in Detectron2. All
            methods are trained with 1x schedule using R50-FPN backbone. The FPS is measured on a single Tesla V100 GPU. SharpContour brings
            significant AP enhancement for DANCE, Mask R-CNN and CondInst. Moreover, SharpContour can achieve competitive performance
            compared with other boundary refinement approaches with the highest efficiency. </p>
        <center>
            <img src="quan.png" style="max-width:80%" /></a>
        </center><br>
        <p align="center"><b>Tab. 1 Comparisons on COCO val2017 and test-dev. </b> </p>
        <p class="w3-left-align"><b>CityScapes</b> Tab. 2 shows the quantitative results of SharpContour on the CityScapes datasets. 
            The training setting for all models are same: trained on fine annotations for 64 epochs, using multi-scale training and ResNet-50 with FPN.</p>
        <center>
            <img src="quan_city.png" style="max-width:40%" /></a>
        </center>
        <p align="center"><b>Tab. 2 Comparisons on CityScapes </b> </p>
    </div>


</div>

<br/>
<br/>

</body>
</html>
